<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A study on the scaling effect of the inference-time computation, investigate the compute-optimal inference method.">
  <meta name="keywords" content="Compute Optimal Inference, AI for Math, Tree Search">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
</head>
<body>




  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://thu-wyz.github.io/">Yangzhen Wu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.cs.cmu.edu/~zhiqings/">Zhiqing Sun</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://lithiumda.github.io/">Shanda Li</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://wellecks.com/">Sean Welleck</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="http://www.cs.cmu.edu/~yiming/">Yiming Yang</a><sup>2</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tsinghua University</span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>2</sup>Carnegie Mellon University</span>
            </div>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span>
                
                <!-- Models Link. -->
                <span class="link-block">
                  <a href=""
                      class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fa fa-network-wired"></i>
                    </span>
                    <span>Models</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-database"></i>
                    </span>
                    <span>Dataset</span>
                    </a>
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The optimal training configurations of large language models (LLMs)
with respect to model sizes and compute budgets have been extensively studied. But how to optimally configure LLMs during inference has not been explored in sufficient depth.
We study compute-optimal inference: designing models and inference strategies that optimally trade off additional inference-time compute for improved performance.
As a first step towards understanding and designing compute-optimal inference methods,
we assessed the effectiveness and computational efficiency of multiple inference strategies such as Greedy Search, Majority Voting, Best-of-N, Weighted Voting, and their variants on two different Tree Search algorithms, involving different model sizes and computational budgets.
We found that a smaller language model with our novel tree search algorithm (Reward Balanced Search) typically achieves a Pareto-optimal trade-off.
These results highlight the potential benefits of deploying smaller models equipped with more sophisticated decoding algorithms in end-devices to enhance problem-solving accuracy.
            </p>
        </div>
        </div>
      </div>
      <!--/ Abstract. -->
  
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Scaling Law. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Inference Time Scaling</h2>
          <figure style="text-align: left;">
            <img src="./static/images/scaling.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto"/>
            <figcaption> The inference computation scaling laws of Pythia models exhibited in error rate on th GSM8K test set.
              We evaluate Pythia model using various sizes and various numbers of sampled solutions for majority voting. The <em>left</em> panel shows the error rate for each model size decreases steadily when the computation increases and converges at the end. The <em>right</em> panel shows the model performances given inference FLOPs budgets. 
              In particular, the three stars highlight the optimal model size under \(10^{12}\), \(10^{13}\), and \(10^{14}\) FLOPs, indicating that the optimal model size can vary given different budgets.</figcaption>
          </figure>
         
        </div>
      </div>
      <!--/ Scaling Law. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Overview of REBASE. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview of Reward Balanced Search (ReBaSe)</h2>
          <figure style="text-align: left;">
          <img src="./static/images/rebase_method.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto"/>
          <br />
          <figcaption>
          The Reward Balanced Search method inherits the exploitation and pruning properties of tree search, while using the reward model alone to estimate the nodes' qualities without additional computation for estimating values by sampling children. 
          The efficiency is achieved by constraining the total expansion width of the tree at a certain depth. 
          REBASE balances the expansion width among the nodes at the same depth based on the rewards given by the Process Reward Model (PRM). See our paper for more information.
        </figcaption>
        </figure>
        </div>
      </div>
      <!--/ Overview of REBASE. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Experiments. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">REBASE Result</h2>
          <figure style="text-align: left;">
          <img src="./static/images/llemma.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto"/>
          <figcaption>
          This figure shows the performance of different inference strategies, where x-axis represents the computation budget in flops and  y-axis denotes the test error rate on MATH dataset the REBASE method consistently outperforms the sampling method and the MCTS. REBASE also 
          saturates later than sampling methods with a higher accuracy.</figcaption>
        </figure>
        </div>
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <img src="./static/images/rebase_table.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto"/>
          <p>Compared to sampling method, REBASE achieves higher accuracy with much less computation.</p>
        </div>
      </div>
      <!--/ Experiments. -->
    </div>
  </section>








  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Website template borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
